from selenium import webdriver
import pandas as pd
import time
import xlsxwriter

# open the website
browser = webdriver.Chrome()
browser.get('http://www.zhenwopai.com/')

# log in
browser.find_element_by_link_text('登录').click()
browser.find_element_by_id('nameOrEmail').send_keys('live4real') # username
browser.find_element_by_id('loginPassword').send_keys('for191726real') # password
browser.find_element_by_css_selector('.green').click()
time.sleep(1)

# direct to the target
browser.find_element_by_css_selector('.tooltipped:nth-child(2) > svg').click()
time.sleep(1)
browser.find_element_by_link_text('文章管理').click()

# obtain the raw data
title = browser.find_elements_by_tag_name('h2')
title_text = []
for element in title: title_text.append(element.text[0:-3])

info = browser.find_elements_by_tag_name('span')
info_text = []
for element in info: info_text.append(element.text)

browser.find_element_by_link_text('最新').click()
author_text =[]
for i in range(60): # should have better solution
    a = i + 1
    css_selector = 'li:nth-child(' + a.__str__() + ') .author'
    author = browser.find_element_by_css_selector(css_selector)
    author_text.append(author.text)

# clean the data
while '正常' in info_text: info_text.remove('正常')
del info_text[0:2]
del info_text[-1]

tag = []
for element in info_text: tag.append(element[0:element.find(' • 2')])
date = []
for element in info_text: date.append(element[(element.find(' • 2')+3):(element.find(' • 2')+13)])
hour = []
for element in info_text: hour.append(element[(element.find(' • 浏览')-5):(element.find(' • 浏览'))])
view = []
for element in info_text: view.append(element[(element.find('浏览计数 ')+5):(element.find(' • 回帖'))])
reply = []
for element in info_text: reply.append(element[(element.find('回帖计数 ')+5):(element.__len__())])

# construct the data frame
data = pd.DataFrame(columns=['文章标题', '作者', '标签', '上传日期', '上传时间', '浏览数', '回复数'])

for i in range(int(len(info_text))):
    data = data.append({'文章标题': title_text[i], '作者': author_text[i],'标签': tag[i], '上传日期': date[i],
                        '上传时间': hour[i], '浏览数': view[i], '回复数': reply[i]}, ignore_index=True)

data = data[(data['上传日期'] > '2020-02-01') & (data['上传日期'] <= '2020-02-16')]

# 删除研报
data_2 = data[~data.标签.str.contains('股票研报')]

# tag齐全的就不需要这两行了
data_2 = data_2[~data_2.文章标题.str.contains('研报')]
data_2 = data_2[~data_2.文章标题.str.contains('五粮液')]

# collect names
name_list = data_2.iloc[:,1].tolist()

finisher = []
for name in name_list:
    if name not in finisher: finisher.append(name)
occurrence = []
for i in range(int(len(finisher))):
    occurrence.append(name_list.count(finisher[i]))

survive = pd.DataFrame(columns=['完成者', '文章数量'])
for i in range(int(len(finisher))):
    survive = survive.append({'完成者': finisher[i], '文章数量': occurrence[i]}, ignore_index=True)

# writer to Excel file
writer = pd.ExcelWriter('e:\\test.xlsx', engine='xlsxwriter')
data_2.to_excel(writer, sheet_name='Sheet1')  # Default position, cell A1.
survive.to_excel(writer, sheet_name='Sheet1', startrow=data_2.shape[0]+5)
writer.save()

browser.quit()
